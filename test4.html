<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Polyphonic Recorder with Voice Recognition</title>
</head>
<body>
    <h1>Polyphonic Recorder with Voice Recognition</h1>
    <button id="start">Start Recording</button>
    <button id="stop" disabled>Stop Recording</button>
    <button id="play" disabled>Play Last Recording</button>
    <button id="startRecognition">Start Voice Recognition</button>
    <button id="stopRecognition" disabled>Stop Voice Recognition</button>
    <label>
        <input type="checkbox" id="echoToggle" checked>
        Echo Cancellation
    </label>
    <p><strong>Voice Recognition Log:</strong></p>
    <div id="recognitionLog" style="border: 1px solid #ddd; padding: 10px; height: 200px; overflow-y: scroll;"></div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioContext;
        let audioBuffer = null; // Holds the previous recording
        let microphoneStream = null;

        let recognition;
        let isRecognitionActive = false;

        const constraints = {
            audio: {
                echoCancellation: true, // does seem to really remove loopback on mike output
                noiseSuppression: false, // seems to be generally nice; does dampen a bit
                autoGainControl: false // this really chews up the live mike track if true
            }
        };

        async function setupAudio() {
            try {
                // Request microphone access with constraints
                microphoneStream = await navigator.mediaDevices.getUserMedia(constraints);

                // Create audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log("Microphone accessed with constraints:", constraints);

                // Set up media recorder
                mediaRecorder = new MediaRecorder(microphoneStream);

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                    console.log("New audio recorded and decoded.");
                    audioChunks = [];
                    document.getElementById("play").disabled = false;
                };
            } catch (err) {
                console.error("Error accessing microphone:", err);
            }
        }

        function setupRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                console.error("Speech Recognition API is not supported in this browser.");
                return;
            }

            recognition = new SpeechRecognition();
            recognition.lang = 'en-US';
            recognition.interimResults = true;

            recognition.onstart = () => {
                console.log("Voice recognition started.");
                isRecognitionActive = true;
                updateLog("Listening...");
                document.getElementById("startRecognition").disabled = true;
                document.getElementById("stopRecognition").disabled = false;
            };

            recognition.onresult = (event) => {
                const interimTranscript = [];
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        console.log("Final transcript:", transcript);
                        updateLog(`Final: ${transcript}`);
                    } else {
                        interimTranscript.push(transcript);
                    }
                }
                if (interimTranscript.length > 0) {
                    updateLog(`Interim: ${interimTranscript.join(" ")}`);
                }
            };

            recognition.onerror = (event) => {
                console.error("Voice recognition error:", event.error);
                updateLog(`Error: ${event.error}`);
            };

            recognition.onend = () => {
                console.log("Voice recognition stopped.");
                isRecognitionActive = false;
                document.getElementById("startRecognition").disabled = false;
                document.getElementById("stopRecognition").disabled = true;
            };
        }

        function updateLog(message) {
            const log = document.getElementById("recognitionLog");
            const newMessage = document.createElement("div");
            newMessage.textContent = message;
            log.appendChild(newMessage);
            log.scrollTop = log.scrollHeight; // Auto-scroll to the bottom
        }

        async function restartWithNewConstraints() {
            if (microphoneStream) {
                microphoneStream.getTracks().forEach((track) => track.stop());
            }

            // Update constraints based on echo cancellation toggle
            constraints.audio.echoCancellation = document.getElementById("echoToggle").checked;
            console.log("New constraints:", constraints);

            await setupAudio();
        }

        document.getElementById("start").onclick = () => {
            if (mediaRecorder && audioContext) {
                if (audioBuffer) {
                    // Play previous recording
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioContext.destination);
                    source.start();
                    console.log("Playing previous recording...");
                }

                // Start recording new input
                mediaRecorder.start();
                console.log("Recording started...");
                document.getElementById("start").disabled = true;
                document.getElementById("stop").disabled = false;
            }
        };

        document.getElementById("stop").onclick = () => {
            if (mediaRecorder) {
                mediaRecorder.stop();
                console.log("Recording stopped.");
                document.getElementById("start").disabled = false;
                document.getElementById("stop").disabled = true;
            }
        };

        document.getElementById("play").onclick = () => {
            if (audioBuffer && audioContext) {
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.start();
                console.log("Playing last recording...");
            }
        };

        document.getElementById("startRecognition").onclick = () => {
            if (recognition && !isRecognitionActive) {
                recognition.start();
            }
        };

        document.getElementById("stopRecognition").onclick = () => {
            if (recognition && isRecognitionActive) {
                recognition.stop();
            }
        };

        document.getElementById("echoToggle").onchange = () => {
            console.log("Echo cancellation toggled.");
            restartWithNewConstraints();
        };

        setupAudio().catch((err) => console.error("Error setting up audio:", err));
        setupRecognition();
    </script>
</body>
</html>

